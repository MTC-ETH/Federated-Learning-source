{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start jupyter server such that the print of the current working dir below is the root directory of the repo\n",
    "Setup the environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/schneech/federated_learning/Federated-Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-12 13:43:44,602 [MainProcess ] [INFO ] [test] [test_class.py / kill_servers / 160] KILLING SERVERS\n",
      "2020-03-12 13:43:44,604 [MainProcess ] [INFO ] [test] [test_class.py / kill_global_server / 122] KILLING GLOBAL SERVER\n",
      "2020-03-12 13:43:44,605 [MainProcess ] [INFO ] [test] [test_class.py / kill_client_interface_node / 129] KILLING CLIENT INTERFACE NODE\n",
      "2020-03-12 13:43:44,607 [MainProcess ] [INFO ] [test] [test_class.py / kill_client_interface / 139] KILLING CLIENT INTERFACE\n",
      "2020-03-12 13:43:44,608 [MainProcess ] [INFO ] [test] [test_class.py / kill_node_servers / 149] KILLINGCLIENTS\n",
      "2020-03-12 13:43:47,724 [MainProcess ] [INFO ] [test] [test_class.py / start_global_server / 303] STARTING UP GLOBAL SERVER\n",
      "2020-03-12 13:43:47,753 [MainProcess ] [INFO ] [test] [test_class.py / start_node_servers / 191] STARTING UP NODES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the commandline is ['/home/schneech/federated_learning/federated_learning/bin/python', 'api/globalserver_task_controller.py', 'C88A33B946']\n",
      "the commandline is ['/home/schneech/federated_learning/federated_learning/bin/python', 'node_task_controller.py', 'c0', 'C88A33B946']\n",
      "the commandline is ['/home/schneech/federated_learning/federated_learning/bin/python', 'node_task_controller.py', 'c1', 'C88A33B946']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import sys\n",
    "os.environ['STATIC_VARIABLES_FILE_PATH'] = \"globalserver/static_variables.json\"\n",
    "os.environ['PATH_TO_GLOBALSERVER'] = \"globalserver/api/\"\n",
    "if os.getcwd().split('/')[-1]!=\"Federated-Learning\":\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from testing.test_class import Testing\n",
    "from globalserver.operator_.operator_class_db import Operator\n",
    "\n",
    "clients = [f\"c{i}\" for i in range(2)]\n",
    "TestSetup = Testing(clients, start_servers=True, clear_logs=True, clear_db=False, interface=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from polybox https://polybox.ethz.ch/index.php/s/W1oSh3H81HqYSQp?path=%2FDatasets%2FKK_Box_Normalized_jsonl and put it into the datasets/kkbox folder. Then split the data into two sets of size 70000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "def split_data():\n",
    "    \n",
    "    with open(f'datasets/kk_box/train_kkbox.jsonl', 'r') as f:\n",
    "        train=f.readlines()\n",
    "    with open(f'datasets/kk_box/test_kkbox.jsonl', 'r') as f:\n",
    "        test=f.readlines()\n",
    "    random.shuffle(train)\n",
    "    train_c1 = train[:70000]\n",
    "    train_c2 = train[70000:140000]\n",
    "    validation_c1 = train[140000:160000]\n",
    "    validation_c2 = train[160000:180000]\n",
    "\n",
    "    with open(f'datasets/train_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(train_c1)\n",
    "    with open(f'datasets/validation_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c1)\n",
    "    with open(f'datasets/test_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c1)\n",
    "\n",
    "    with open(f'datasets/train_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(train_c2)\n",
    "    with open(f'datasets/validation_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c2)\n",
    "    with open(f'datasets/test_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c2)\n",
    "        \n",
    "# split_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the experimental setup in several steps. First we define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kknox_nn(param_dict):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation=tf.nn.relu, input_dim=61))\n",
    "    model.add(Dense(50, activation=tf.nn.relu))\n",
    "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=param_dict['lr']),  # momentum=mt),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define all the metadata as well as the training configurations. Most important: rounds, epochs, batch_size, steps_per_epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dict = {\"model_function\": #here we set how to run our model function. In the operator it will run kknox_nn({\"lr\": 0.1})\n",
    "              {\n",
    "    \"function\": kknox_nn,\n",
    "    \"parameters\": {\n",
    "        \"lr\": 0.20014587438532283\n",
    "    }\n",
    "},\n",
    "    \"git_version\": 'e9339081b76ad3a89b1862bd38d8af26f0541f1c', # the git commit version (for now set manually)\n",
    "    \"protocol\": 'NN', # the protocol name. NN is for neural networks\n",
    "    \"model_name\": \"test_model\",\n",
    "    \"model_description\": \"this model is just to test the db\",\n",
    "    \"testing\": True, # This flag is helpful if you do not want to keep the created models. When you run Testing with cleardb=True it will clear all models and experiments with testing flag.\n",
    "    \"rounds\": 2,\n",
    "    \"round\": [\"fetch_model\", \"train_model\", \"send_training_loss\", \"send_validation_loss\", \"send_model\", \"aggregate\"],\n",
    "    \"final_round\":[\"fetch_model\", \"send_training_loss\", \"send_validation_loss\",\"send_test_loss\"],\n",
    "    \"training_config\": { # standard configuration for the training setup\n",
    "        'epochs': 1,\n",
    "        'verbose': 1,\n",
    "        'batch_size': 2000,\n",
    "        \"validation_steps\": 8,#should be at most len(validation data)/batch_size\n",
    "        \"test_steps\": 8, #should be at most  len(test data)/batch_size\n",
    "        \"steps_per_epoch\": 65, #should be at most  len(training data)/batch_size\n",
    "        \"dataset\": \"\",\n",
    "\n",
    "        \"skmetrics\":[\"f1_score\"],\n",
    "        \"tfmetrics\":[\"AUC\"]\n",
    "    },\n",
    "   \"clients\": clients,\n",
    "    \"experiment_name\": \"kkbox\",\n",
    "    \"experiment_description\": f\"desc if nice experiment\",\n",
    "        \"preprocessing\": {\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-12 13:40:36,892 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneech/federated_learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-03-12 13:40:36,914 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 170] 5e6a2dc4f8219093ef163755\n",
      "2020-03-12 13:40:36,915 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef163756'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                3100      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-12 13:40:51,929 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef163757'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-03-12 13:40:56,933 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef163759'), 'task_order': 3, 'task_name': 'send_validation_loss', 'task_status': 'scheduled'}\n",
      "2020-03-12 13:41:01,938 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef16375b'), 'task_order': 5, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-03-12 13:41:01,941 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 230] Aggregating...\n",
      "2020-03-12 13:41:01,956 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 157] Average loss of {'f1_score': 0.0, 'AUC': 0.6788454651832581} reached in this round.\n",
      "2020-03-12 13:41:06,961 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef16375e'), 'task_order': 8, 'task_name': 'send_training_loss', 'task_status': 'scheduled'}\n",
      "2020-03-12 13:41:11,967 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef16375f'), 'task_order': 9, 'task_name': 'send_validation_loss', 'task_status': 'scheduled'}\n",
      "2020-03-12 13:41:16,974 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef163761'), 'task_order': 11, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-03-12 13:41:16,976 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 230] Aggregating...\n",
      "2020-03-12 13:41:16,990 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 157] Average loss of {'f1_score': 0.0, 'AUC': 0.70260289311409} reached in this round.\n",
      "2020-03-12 13:41:21,997 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef163764'), 'task_order': 14, 'task_name': 'send_validation_loss', 'task_status': 'scheduled'}\n",
      "2020-03-12 13:41:27,001 [MainProcess ] [DEBUG] [test] [operator_class_db.py / start_experiment / 182] Working on {'task_id': ObjectId('5e6a2dc4f8219093ef163765'), 'task_order': 15, 'task_name': 'send_test_loss', 'task_status': 'scheduled'}\n",
      "2020-03-12 13:41:32,006 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 193] Experiment 5e6a2dc4f8219093ef163755 finished\n",
      "2020-03-12 13:41:32,008 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 157] Average loss of {'f1_score': 0.0, 'AUC': 0.7031293511390686} reached in this round.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ObjectId('5e6a2dc4f8219093ef163755'),\n",
       " [{'aggregated_metric': {'f1_score': 0.0, 'AUC': 0.6788454651832581},\n",
       "   'additional_metrics': []},\n",
       "  {'aggregated_metric': {'f1_score': 0.0, 'AUC': 0.70260289311409},\n",
       "   'additional_metrics': []}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "operator = Operator()\n",
    "operator.define_and_start_experiment(setup_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
