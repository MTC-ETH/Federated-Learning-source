{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start jupyter server such that the print of the current working dir below is the root directory of the repo\n",
    "Setup the environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/schneebi/PycharmProjects/federated-learning/Federated-Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:01:18,078 [MainProcess ] [INFO ] [test] [test_class.py / kill_servers / 194] KILLING SERVERS\n",
      "2020-04-01 13:01:18,080 [MainProcess ] [INFO ] [test] [test_class.py / kill_global_server / 156] KILLING GLOBAL SERVER\n",
      "2020-04-01 13:01:18,082 [MainProcess ] [INFO ] [test] [test_class.py / kill_client_interface_node / 163] KILLING CLIENT INTERFACE NODE\n",
      "2020-04-01 13:01:18,084 [MainProcess ] [INFO ] [test] [test_class.py / kill_client_interface / 173] KILLING CLIENT INTERFACE\n",
      "2020-04-01 13:01:18,085 [MainProcess ] [INFO ] [test] [test_class.py / kill_node_servers / 183] KILLINGCLIENTS\n",
      "2020-04-01 13:01:21,242 [MainProcess ] [INFO ] [test] [test_class.py / start_global_server / 337] STARTING UP GLOBAL SERVER\n",
      "2020-04-01 13:01:21,259 [MainProcess ] [INFO ] [test] [test_class.py / start_node_servers / 225] STARTING UP NODES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the commandline is ['/home/schneebi/PycharmProjects/federated-learning/venv/bin/python', 'api/globalserver_task_controller.py', 'C88A33B946']\n",
      "the commandline is ['/home/schneebi/PycharmProjects/federated-learning/venv/bin/python', 'node_task_controller.py', 'c0', 'C88A33B946']\n",
      "the commandline is ['/home/schneebi/PycharmProjects/federated-learning/venv/bin/python', 'node_task_controller.py', 'c1', 'C88A33B946']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import sys\n",
    "os.environ['STATIC_VARIABLES_FILE_PATH'] = \"globalserver/static_variables.json\"\n",
    "os.environ['PATH_TO_GLOBALSERVER'] = \"globalserver/api/\"\n",
    "if os.getcwd().split('/')[-1]!=\"Federated-Learning\":\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "from testing.test_class import Testing\n",
    "from globalserver.operator_.operator_class_db import Operator\n",
    "\n",
    "clients = [f\"c{i}\" for i in range(2)]\n",
    "TestSetup = Testing(clients, start_servers=True, clear_logs=True, clear_db=False, interface=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from polybox https://polybox.ethz.ch/index.php/s/W1oSh3H81HqYSQp?path=%2FDatasets%2FKK_Box_Normalized_jsonl and put it into the datasets/kkbox folder. Then split the data into two sets of size 70000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "def split_data():\n",
    "    \n",
    "    with open(f'datasets/kk_box/train_kkbox.jsonl', 'r') as f:\n",
    "        train=f.readlines()\n",
    "    with open(f'datasets/kk_box/test_kkbox.jsonl', 'r') as f:\n",
    "        test=f.readlines()\n",
    "    random.shuffle(train)\n",
    "    train_c1 = train[:70000]\n",
    "    train_c2 = train[70000:140000]\n",
    "    validation_c1 = train[140000:160000]\n",
    "    validation_c2 = train[160000:180000]\n",
    "\n",
    "    with open(f'datasets/train_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(train_c1)\n",
    "    with open(f'datasets/validation_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c1)\n",
    "    with open(f'datasets/test_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c1)\n",
    "\n",
    "    with open(f'datasets/train_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(train_c2)\n",
    "    with open(f'datasets/validation_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c2)\n",
    "    with open(f'datasets/test_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(validation_c2)\n",
    "        \n",
    "# split_data()\n",
    "#experiment_run_1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the experimental setup in several steps. First we define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kknox_nn(param_dict):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation=tf.nn.relu, input_dim=61))\n",
    "    model.add(Dense(50, activation=tf.nn.relu))\n",
    "    model.add(Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=param_dict['lr']),  # momentum=mt),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the upkeep function. This function is run after every aggregation step. We simply want to shuffle the data. This is optional. Just set it to None below if you dont need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upkeep_function(self, experiment_document):\n",
    "    import random\n",
    "    with open(f'datasets/train_c0.jsonl', 'r') as f:\n",
    "        train_c1 = f.readlines()\n",
    "    random.shuffle(train_c1)\n",
    "    with open(f'datasets/train_c0.jsonl', 'w+') as f:\n",
    "        f.writelines(train_c1)\n",
    "\n",
    "    with open(f'datasets/train_c1.jsonl', 'r') as f:\n",
    "        train_c2 = f.readlines()\n",
    "    random.shuffle(train_c2)\n",
    "    with open(f'datasets/train_c1.jsonl', 'w+') as f:\n",
    "        f.writelines(train_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(batch):\n",
    "\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_function(self, experiment_document, aggregated_metric):\n",
    "        if len(experiment_document['validation_results'])>2  :\n",
    "            return True, [aggregated_metric['AUC']]\n",
    "        else:\n",
    "            return False, [aggregated_metric['AUC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define all the metadata as well as the training configurations. Most important: rounds, epochs, batch_size, steps_per_epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dict = {\"model_function\": #here we set how to run our model function. In the operator it will run kknox_nn({\"lr\": 0.1})\n",
    "              {\n",
    "    \"function\": kknox_nn,\n",
    "    \"parameters\": {\n",
    "        \"lr\": 0.20014587438532283\n",
    "    }\n",
    "},\n",
    "    \"git_version\": 'e9339081b76ad3a89b1862bd38d8af26f0541f1c', # the git commit version (for now set manually)\n",
    "    \"protocol\": 'NN', # the protocol name. NN is for neural networks\n",
    "    \"model_name\": \"test_model\",\n",
    "    \"model_description\": \"this model is just to test the db\",\n",
    "    \"testing\": True, # This flag is helpful if you do not want to keep the created models. When you run Testing with cleardb=True it will clear all models and experiments with testing flag.\n",
    "    \"rounds\": 2, # number of rounds of node-server communication to run\n",
    "    \"training_config\": { # standard configuration for the training setup\n",
    "        'epochs': 5,\n",
    "        'verbose': 0,\n",
    "        'batch_size': 10,\n",
    "        \"validation_steps\": 12,#should be at most len(validation data)/batch_size\n",
    "        \"test_steps\": 70, #should be at most  len(test data)/batch_size\n",
    "        \"steps_per_epoch\": 70, #should be at most  len(training data)/batch_size\n",
    "\n",
    "        \"skmetrics\":[\"f1_score\"],\n",
    "        \"tfmetrics\":[\"AUC\",\"Accuracy\"]\n",
    "    },\n",
    "   \"clients\": clients,\n",
    "    \"experiment_name\": \"kkbox\",\n",
    "    \"experiment_description\": f\"desc if nice experiment\",\n",
    "        \"preprocessing\": {\n",
    "    },\n",
    "    \"stop_function\":stop_function\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the hyperparameters we want to tune. Follow optuna doc: https://optuna.readthedocs.io/en/stable/reference/trial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunable_parameters = [\n",
    "    {\n",
    "            'parameter_key_list': ['model_function', 'parameters', 'lr'],\n",
    "            'function_name': 'suggest_uniform',\n",
    "            'function_arguments': {'name': 'lr', 'low': 0.001, 'high': 0.5},\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we define the objective we want to minimize. In this example we simply take the aggregated cross entropy loss we got in the last run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_loss_function(metrics):\n",
    "    return metrics['aggregated_metric']['AUC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the setup.\n",
    "We can now run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:01:22,571 [MainProcess ] [INFO ] [test] [operator_class_db.py / objective / 370] TEST WITH [{\"parameter_key_list\": [\"model_function\", \"parameters\", \"lr\"], \"function_name\": \"suggest_uniform\", \"function_arguments\": {\"name\": \"lr\", \"low\": 0.001, \"high\": 0.5}}]\n",
      "2020-04-01 13:01:22,695 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'version'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=None)\n",
      "2020-04-01 13:01:22,708 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'version'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=None)\n",
      "2020-04-01 13:01:22,727 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-04-01 13:01:22,786 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 167] 5e84748255fbdadaa7326ac1\n",
      "2020-04-01 13:01:22,789 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84748255fbdadaa7326ac2'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                3100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:01:37,799 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84748255fbdadaa7326ac3'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:01:42,807 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84748255fbdadaa7326ac6'), 'task_order': 4, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:01:42,808 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:01:42,861 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.48571428571428577, 'AUC': 0.761476457118988, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:01:42,862 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:01:47,871 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84748255fbdadaa7326ac8'), 'task_order': 6, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:01:52,876 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84748255fbdadaa7326acb'), 'task_order': 9, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:01:52,878 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:01:52,918 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.5357142857142858, 'AUC': 0.7212255299091339, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:01:52,919 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:01:57,931 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84748255fbdadaa7326ace'), 'task_order': 12, 'task_name': 'send_validation_loss', 'task_status': 'done'}\n",
      "2020-04-01 13:01:57,932 [MainProcess ] [INFO ] [test] [operator_class_db.py / _experiment_stop_condition / 401] Experiment 5e84748255fbdadaa7326ac1 finished\n",
      "2020-04-01 13:01:57,934 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.600942850053759, 'AUC': 0.7792638540267944, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:01:57,936 [MainProcess ] [INFO ] [test] [operator_class_db.py / _save_aggregated_metrics / 413] Please make sure that the stop function is described in the experiment\n",
      "\u001b[32m[I 2020-04-01 13:01:58,033]\u001b[0m Finished trial#0 resulted in value: 0.7792638540267944. Current best value is 0.7792638540267944 with parameters: {'lr': 0.47187871913858476}.\u001b[0m\n",
      "2020-04-01 13:01:58,034 [MainProcess ] [INFO ] [test] [operator_class_db.py / objective / 370] TEST WITH [{\"parameter_key_list\": [\"model_function\", \"parameters\", \"lr\"], \"function_name\": \"suggest_uniform\", \"function_arguments\": {\"name\": \"lr\", \"low\": 0.001, \"high\": 0.5}}]\n",
      "2020-04-01 13:01:58,084 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-04-01 13:01:58,117 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 167] 5e8474a655fbdadaa7326ad1\n",
      "2020-04-01 13:01:58,119 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474a655fbdadaa7326ad2'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ewrgfewrgr\n",
      "{'aggregated_metric': {'f1_score': 0.600942850053759, 'AUC': 0.7792638540267944, 'Accuracy': 0.0}, 'additional_metrics': [0.7792638540267944]}\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                3100      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:02:13,135 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474a655fbdadaa7326ad3'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:02:18,143 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474a655fbdadaa7326ad6'), 'task_order': 4, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:02:18,145 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:02:18,163 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.4019607843137255, 'AUC': 0.7232657968997955, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:02:18,164 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:02:23,171 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474a655fbdadaa7326ad8'), 'task_order': 6, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:02:28,178 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474a655fbdadaa7326adb'), 'task_order': 9, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:02:28,180 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:02:28,200 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.6190476190476191, 'AUC': 0.7305203676223755, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:02:28,201 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:02:33,211 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474a655fbdadaa7326ade'), 'task_order': 12, 'task_name': 'send_validation_loss', 'task_status': 'done'}\n",
      "2020-04-01 13:02:33,212 [MainProcess ] [INFO ] [test] [operator_class_db.py / _experiment_stop_condition / 401] Experiment 5e8474a655fbdadaa7326ad1 finished\n",
      "2020-04-01 13:02:33,213 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.600942850053759, 'AUC': 0.8021450936794281, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:02:33,213 [MainProcess ] [INFO ] [test] [operator_class_db.py / _save_aggregated_metrics / 413] Please make sure that the stop function is described in the experiment\n",
      "\u001b[32m[I 2020-04-01 13:02:33,313]\u001b[0m Finished trial#1 resulted in value: 0.8021450936794281. Current best value is 0.7792638540267944 with parameters: {'lr': 0.47187871913858476}.\u001b[0m\n",
      "2020-04-01 13:02:33,314 [MainProcess ] [INFO ] [test] [operator_class_db.py / objective / 370] TEST WITH [{\"parameter_key_list\": [\"model_function\", \"parameters\", \"lr\"], \"function_name\": \"suggest_uniform\", \"function_arguments\": {\"name\": \"lr\", \"low\": 0.001, \"high\": 0.5}}]\n",
      "2020-04-01 13:02:33,371 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-04-01 13:02:33,411 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 167] 5e8474c955fbdadaa7326ae1\n",
      "2020-04-01 13:02:33,413 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474c955fbdadaa7326ae2'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ewrgfewrgr\n",
      "{'aggregated_metric': {'f1_score': 0.600942850053759, 'AUC': 0.8021450936794281, 'Accuracy': 0.0}, 'additional_metrics': [0.8021450936794281]}\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 50)                3100      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:02:48,427 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474c955fbdadaa7326ae3'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:02:53,433 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474c955fbdadaa7326ae6'), 'task_order': 4, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:02:53,435 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:02:53,487 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.3666666666666667, 'AUC': 0.775119960308075, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:02:53,489 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:02:58,499 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474c955fbdadaa7326ae8'), 'task_order': 6, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:03:03,505 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474c955fbdadaa7326aeb'), 'task_order': 9, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:03:03,506 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:03:03,548 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.5357142857142858, 'AUC': 0.7130999267101288, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:03:03,549 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:03:08,561 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474c955fbdadaa7326aee'), 'task_order': 12, 'task_name': 'send_validation_loss', 'task_status': 'done'}\n",
      "2020-04-01 13:03:08,562 [MainProcess ] [INFO ] [test] [operator_class_db.py / _experiment_stop_condition / 401] Experiment 5e8474c955fbdadaa7326ae1 finished\n",
      "2020-04-01 13:03:08,564 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.600942850053759, 'AUC': 0.7943803369998932, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:03:08,566 [MainProcess ] [INFO ] [test] [operator_class_db.py / _save_aggregated_metrics / 413] Please make sure that the stop function is described in the experiment\n",
      "\u001b[32m[I 2020-04-01 13:03:08,667]\u001b[0m Finished trial#2 resulted in value: 0.7943803369998932. Current best value is 0.7792638540267944 with parameters: {'lr': 0.47187871913858476}.\u001b[0m\n",
      "2020-04-01 13:03:08,668 [MainProcess ] [INFO ] [test] [operator_class_db.py / objective / 370] TEST WITH [{\"parameter_key_list\": [\"model_function\", \"parameters\", \"lr\"], \"function_name\": \"suggest_uniform\", \"function_arguments\": {\"name\": \"lr\", \"low\": 0.001, \"high\": 0.5}}]\n",
      "2020-04-01 13:03:08,715 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-04-01 13:03:08,750 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 167] 5e8474ec55fbdadaa7326af1\n",
      "2020-04-01 13:03:08,752 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474ec55fbdadaa7326af2'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ewrgfewrgr\n",
      "{'aggregated_metric': {'f1_score': 0.600942850053759, 'AUC': 0.7943803369998932, 'Accuracy': 0.0}, 'additional_metrics': [0.7943803369998932]}\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 50)                3100      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:03:23,767 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474ec55fbdadaa7326af3'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:03:28,775 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474ec55fbdadaa7326af6'), 'task_order': 4, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:03:28,776 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:03:28,820 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.2, 'AUC': 0.7830513715744019, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:03:28,821 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:03:33,831 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474ec55fbdadaa7326af8'), 'task_order': 6, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:03:38,839 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474ec55fbdadaa7326afb'), 'task_order': 9, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:03:38,841 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:03:38,858 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.5357142857142858, 'AUC': 0.7491225004196167, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:03:38,859 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:03:43,870 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e8474ec55fbdadaa7326afe'), 'task_order': 12, 'task_name': 'send_validation_loss', 'task_status': 'done'}\n",
      "2020-04-01 13:03:43,872 [MainProcess ] [INFO ] [test] [operator_class_db.py / _experiment_stop_condition / 401] Experiment 5e8474ec55fbdadaa7326af1 finished\n",
      "2020-04-01 13:03:43,874 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.5815910249872513, 'AUC': 0.7972713708877563, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:03:43,876 [MainProcess ] [INFO ] [test] [operator_class_db.py / _save_aggregated_metrics / 413] Please make sure that the stop function is described in the experiment\n",
      "\u001b[32m[I 2020-04-01 13:03:43,995]\u001b[0m Finished trial#3 resulted in value: 0.7972713708877563. Current best value is 0.7792638540267944 with parameters: {'lr': 0.47187871913858476}.\u001b[0m\n",
      "2020-04-01 13:03:43,997 [MainProcess ] [INFO ] [test] [operator_class_db.py / objective / 370] TEST WITH [{\"parameter_key_list\": [\"model_function\", \"parameters\", \"lr\"], \"function_name\": \"suggest_uniform\", \"function_arguments\": {\"name\": \"lr\", \"low\": 0.001, \"high\": 0.5}}]\n",
      "2020-04-01 13:03:44,040 [MainProcess ] [DEBUG] [test] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-04-01 13:03:44,072 [MainProcess ] [INFO ] [test] [operator_class_db.py / start_experiment / 167] 5e84751055fbdadaa7326b01\n",
      "2020-04-01 13:03:44,074 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84751055fbdadaa7326b02'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ewrgfewrgr\n",
      "{'aggregated_metric': {'f1_score': 0.5815910249872513, 'AUC': 0.7972713708877563, 'Accuracy': 0.0}, 'additional_metrics': [0.7972713708877563]}\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 50)                3100      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 13:03:59,087 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84751055fbdadaa7326b03'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:04:04,095 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84751055fbdadaa7326b06'), 'task_order': 4, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:04:04,097 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:04:04,114 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.15384615384615383, 'AUC': 0.7481829822063446, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:04:04,115 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:04:09,123 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84751055fbdadaa7326b08'), 'task_order': 6, 'task_name': 'train_model', 'task_status': 'scheduled'}\n",
      "2020-04-01 13:04:14,129 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84751055fbdadaa7326b0b'), 'task_order': 9, 'task_name': 'aggregate', 'task_status': 'not_scheduled'}\n",
      "2020-04-01 13:04:14,130 [MainProcess ] [INFO ] [test] [operator_class_db.py / aggregate / 250] Aggregating...\n",
      "2020-04-01 13:04:14,147 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.5357142857142858, 'AUC': 0.7263728976249695, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:04:14,148 [MainProcess ] [INFO ] [test] [operator_class_db.py / _early_experiment_stop / 459] Please make sure that the stop function is described in the experiment\n",
      "2020-04-01 13:04:19,159 [MainProcess ] [DEBUG] [test] [operator_utils.py / get_current_task / 94] Working on {'task_id': ObjectId('5e84751055fbdadaa7326b0e'), 'task_order': 12, 'task_name': 'send_validation_loss', 'task_status': 'done'}\n",
      "2020-04-01 13:04:19,160 [MainProcess ] [INFO ] [test] [operator_class_db.py / _experiment_stop_condition / 401] Experiment 5e84751055fbdadaa7326b01 finished\n",
      "2020-04-01 13:04:19,162 [MainProcess ] [INFO ] [test] [operator_utils.py / aggregate_loss / 197] Average loss of {'f1_score': 0.5547619047619048, 'AUC': 0.800878643989563, 'Accuracy': 0.0} reached in this round.\n",
      "2020-04-01 13:04:19,164 [MainProcess ] [INFO ] [test] [operator_class_db.py / _save_aggregated_metrics / 413] Please make sure that the stop function is described in the experiment\n",
      "\u001b[32m[I 2020-04-01 13:04:19,277]\u001b[0m Finished trial#4 resulted in value: 0.800878643989563. Current best value is 0.7792638540267944 with parameters: {'lr': 0.47187871913858476}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ewrgfewrgr\n",
      "{'aggregated_metric': {'f1_score': 0.5547619047619048, 'AUC': 0.800878643989563, 'Accuracy': 0.0}, 'additional_metrics': [0.800878643989563]}\n"
     ]
    }
   ],
   "source": [
    "operator = Operator()\n",
    "import optuna\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(lambda trial: operator.objective(trial, setup_dict, tunable_parameters, trial_loss_function),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
