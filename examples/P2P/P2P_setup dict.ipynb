{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/schneebi/PycharmProjects/federated-learning/Federated-Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 13:18:22,402 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / kill_servers / 194] KILLING SERVERS\n",
      "2020-05-13 13:18:22,403 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / kill_global_server / 156] KILLING GLOBAL SERVER\n",
      "2020-05-13 13:18:22,404 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / kill_client_interface_node / 163] KILLING CLIENT INTERFACE NODE\n",
      "2020-05-13 13:18:22,404 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / kill_client_interface / 173] KILLING CLIENT INTERFACE\n",
      "2020-05-13 13:18:22,405 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / kill_node_servers / 183] KILLINGCLIENTS\n",
      "2020-05-13 13:18:25,553 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / start_global_server / 337] STARTING UP GLOBAL SERVER\n",
      "2020-05-13 13:18:25,569 [MainProcess ] [INFO ] [OPERATOR] [test_class.py / start_node_servers / 225] STARTING UP NODES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the commandline is ['/home/schneebi/PycharmProjects/federated-learning/venv/bin/python', 'api/globalserver_task_controller.py', 'C88A33B946']\n",
      "the commandline is ['/home/schneebi/PycharmProjects/federated-learning/venv/bin/python', 'node_task_controller.py', 'c0', 'C88A33B946']\n",
      "the commandline is ['/home/schneebi/PycharmProjects/federated-learning/venv/bin/python', 'node_task_controller.py', 'c1', 'C88A33B946']\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2019-2020, ETH Zurich, Media Technology Center\n",
    "#\n",
    "# This file is part of Federated Learning Project at MTC.\n",
    "#\n",
    "# Federated Learning is a free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Lesser Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# Federated Learning is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU Lesser Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU Lesser Public License\n",
    "# along with Federated Learning.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "The Python implementation of the MTC Federated Learning Example Operator.\n",
    "\n",
    "This is an example how to use the Operator Class.\n",
    "\n",
    "Look at operator_class_db.py for all callable functions.\n",
    "\n",
    "The example creates a model and runs 10 rounds of send_model_to_nodes->training_on_nodes->\n",
    "send_back_to_server->aggregate_gradients_to_get_new_global_models\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import sys\n",
    "if os.getcwd().split('/')[-1]!=\"Federated-Learning\":\n",
    "    os.chdir('../..')\n",
    "print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "os.environ['STATIC_VARIABLES_FILE_PATH'] = \"globalserver/static_variables.json\"\n",
    "\n",
    "os.environ['PATH_TO_GLOBALSERVER'] = \"globalserver/api/\"\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import logging\n",
    "from globalserver.operator_.operator_class_db import Operator\n",
    "from testing.test_class import Testing\n",
    "from globalserver.operator_.utils import operator_utils\n",
    "import json\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "clients = ['c0', 'c1']\n",
    "TestSetup = Testing(clients, start_servers=True, clear_logs=True, clear_db=False, interface=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_compiled_model_P2P(param_dict):\n",
    "\n",
    "    model = xgb.Booster(param_dict['params'], [param_dict['example']])\n",
    "    return model\n",
    "\n",
    "with open('datasets/test_c0.jsonl') as f:\n",
    "    line = list(json.loads(f.readline()).values())\n",
    "\n",
    "X_example = [line[:-1], line[:-1]]\n",
    "y_example = [line[-1], line[-1]]\n",
    "example = xgb.DMatrix(X_example, label=y_example)\n",
    "param_dict={'params':{'max_depth': 8, 'subsample': 0.5, 'eta': 0.01, 'max_delta_step': 0,\n",
    "                        'scale_pos_weight': 1.5, 'objective': 'binary:logitraw',\n",
    "                        'tree_method': 'hist', 'max_bin': 250, 'colsample_bytree': 1},'example':example}\n",
    "\n",
    "\n",
    "def preprocessing(batch):\n",
    "    batch['label'] = [int(value) for value in batch['label']]\n",
    "    for key in batch:\n",
    "        batch[key] = [0 if value == '(not_set)' else float(value) for value in batch[key]]\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "\n",
    "# here we specify rounds a bit differently, since clients need to perform tasks one after another\n",
    "round = []\n",
    "# for i in range(len(clients)):\n",
    "for client in clients:\n",
    "    round.extend([(\"fetch_model\", client), (\"train_model\", client), (\"send_model\", client),\n",
    "                  (\"send_validation_loss\", client), (\"aggregate\", 0)])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dict = {\"model_function\": {\n",
    "    \"function\": get_compiled_model_P2P,\n",
    "    \"parameters\": param_dict,\n",
    "    },\n",
    "        \"git_version\": 'e9339081b76ad3a89b1862bd38d8af26f0541f1c',\n",
    "        \"protocol\": 'P2P',\n",
    "        \"model_name\": \"test_model\",\n",
    "        \"model_description\": \"this model is just to test the db\",\n",
    "        \"testing\": True,\n",
    "        \"training_config\": {\n",
    "        \"verbosity\": 1,\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 100,\n",
    "        \"nthread\": -1,\n",
    "        \"client_steps_per_round\": 1,\n",
    "        \"nr_clients\": len(clients),\n",
    "        \"skmetrics\": [\"f1_score\",\"accuracy_score\"],\n",
    "        \"tfmetrics\": [\"AUC\", \"Accuracy\"],\n",
    "\n",
    "        \"dataset\": \"\",\n",
    "\n",
    "    },\n",
    "    \"rounds\": 2,\n",
    "    \"round\":round,\n",
    "    \"final_round\":[],\n",
    "    \"clients\": clients,\n",
    "    \"experiment_name\": \"kkbox\",\n",
    "    \"experiment_description\": f\"desc if nice experiment\",\n",
    "    \"preprocessing\": {\n",
    "    \"noise\": {\n",
    "        \"epsilon\": 1,\n",
    "        \"delta\": 0.2\n",
    "    },\n",
    "    \"cast_to_float\": \"\",\n",
    "    \"feature_selection\": [f\"column{i}\" for i in range(5,50)],\n",
    "    \"preprocessing_function\": preprocessing\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 13:19:04,357 [MainProcess ] [DEBUG] [OPERATOR] [cmd.py / execute / 719] Popen(['git', 'cat-file', '--batch-check'], cwd=/home/schneebi/PycharmProjects/federated-learning/Federated-Learning, universal_newlines=False, shell=None, istream=<valid stream>)\n",
      "2020-05-13 13:19:04,405 [MainProcess ] [INFO ] [OPERATOR] [operator_class_db.py / start_experiment / 171] 5ebbd7a871ead263b014c879\n",
      "2020-05-13 13:19:04,407 [MainProcess ] [DEBUG] [OPERATOR] [operator_utils.py / get_current_task / 96] Working on {'task_id': ObjectId('5ebbd7a871ead263b014c87a'), 'task_order': 0, 'task_name': 'fetch_model', 'task_status': 'not_scheduled'}\n",
      "2020-05-13 13:19:19,426 [MainProcess ] [DEBUG] [OPERATOR] [operator_utils.py / get_current_task / 96] Working on {'task_id': ObjectId('5ebbd7a871ead263b014c87b'), 'task_order': 1, 'task_name': 'train_model', 'task_status': 'scheduled'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ObjectId('5ebbd7a871ead263b014c879'),\n",
       " {'aggregated_metric': [], 'additional_metrics': []})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from globalserver.operator_.operator_class_db import Operator\n",
    "\n",
    "operator = Operator()\n",
    "operator.define_and_start_experiment(setup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
